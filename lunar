{"cells":[{"cell_type":"markdown","metadata":{"id":"LbZcI9ZXHl3a"},"source":["# Deep Q-Learning for Lunar Landing"]},{"cell_type":"markdown","metadata":{"id":"E8yPRjteXgPb"},"source":["## Part 0 - Installing the required packages and importing the libraries"]},{"cell_type":"markdown","metadata":{"id":"slEm5teGWjWU"},"source":["### Installing Gymnasium"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"dbnq3XpoKa_7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727527599089,"user_tz":-330,"elapsed":103520,"user":{"displayName":"Shibangi Sankarsan","userId":"12830922084921040479"}},"outputId":"06aff307-993c-4feb-ebcf-4a5ee473d21e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gymnasium\n","  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n","Collecting farama-notifications>=0.0.1 (from gymnasium)\n","  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n","Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n","Installing collected packages: farama-notifications, gymnasium\n","Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n","Requirement already satisfied: gymnasium[accept-rom-license,atari] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (4.12.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n","Collecting autorom~=0.4.2 (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari])\n","  Downloading AutoROM-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n","Collecting shimmy<1.0,>=0.1.0 (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[accept-rom-license,atari])\n","  Downloading Shimmy-0.2.1-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]) (8.1.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]) (4.66.5)\n","Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari])\n","  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting ale-py~=0.8.1 (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[accept-rom-license,atari])\n","  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[accept-rom-license,atari]) (6.4.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license,atari]) (2024.8.30)\n","Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n","Downloading Shimmy-0.2.1-py3-none-any.whl (25 kB)\n","Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: AutoROM.accept-rom-license\n","  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446661 sha256=c9a04ab0e5d1a617c719b8d85045f7f618bdb65a9e3ef6b24040807df75059a0\n","  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n","Successfully built AutoROM.accept-rom-license\n","Installing collected packages: ale-py, shimmy, AutoROM.accept-rom-license, autorom\n","Successfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.4.2 shimmy-0.2.1\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  swig4.0\n","Suggested packages:\n","  swig-doc swig-examples swig4.0-examples swig4.0-doc\n","The following NEW packages will be installed:\n","  swig swig4.0\n","0 upgraded, 2 newly installed, 0 to remove and 49 not upgraded.\n","Need to get 1,116 kB of archives.\n","After this operation, 5,542 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n","Fetched 1,116 kB in 2s (722 kB/s)\n","Selecting previously unselected package swig4.0.\n","(Reading database ... 123614 files and directories currently installed.)\n","Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n","Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n","Selecting previously unselected package swig.\n","Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n","Unpacking swig (4.0.2-1ubuntu1) ...\n","Setting up swig4.0 (4.0.2-1ubuntu1) ...\n","Setting up swig (4.0.2-1ubuntu1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.12.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (0.0.4)\n","Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n","  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.6.0)\n","Collecting swig==4.* (from gymnasium[box2d])\n","  Downloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.6 kB)\n","Downloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: box2d-py\n","  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2349139 sha256=997fab9d84640cb11d4990a28318583166ea0d43509b5fad30fcae7c2e17fc3c\n","  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n","Successfully built box2d-py\n","Installing collected packages: swig, box2d-py\n","Successfully installed box2d-py-2.3.5 swig-4.2.1\n"]}],"source":["!pip install gymnasium\n","!pip install \"gymnasium[atari, accept-rom-license]\"\n","!apt-get install -y swig\n","!pip install gymnasium[box2d]"]},{"cell_type":"markdown","metadata":{"id":"brqiMN3UW9T9"},"source":["### Importing the libraries"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"mZaKXP_aMl9O","executionInfo":{"status":"ok","timestamp":1727527737956,"user_tz":-330,"elapsed":4935,"user":{"displayName":"Shibangi Sankarsan","userId":"12830922084921040479"}}},"outputs":[],"source":["import os\n","import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.autograd as autograd\n","from torch.autograd import Variable\n","from collections import deque, namedtuple"]},{"cell_type":"markdown","metadata":{"id":"EzlDKXvkXzGI"},"source":["## Part 1 - Building the AI"]},{"cell_type":"markdown","metadata":{"id":"UtG6Zc83YYy3"},"source":["### Creating the architecture of the Neural Network"]},{"cell_type":"code","source":["class Network(nn.Module):\n","  def __init__(self, state_size, action_size, seed=42) ->None:\n","    super(Network, self).__init__()\n","    self.seed = torch.manual_seed(seed)\n","    self.fc1 = nn.Linear(state_size, 64)\n","    self.fc2 = nn.Linear(64, 64)\n","    self.fc3 = nn.Linear(64, action_size)\n","\n","  def forward(self, state):\n","    x=self.fc1(state)\n","    x= F.relu(x)\n","    x=self.fc2(x)\n","    x= F.relu(x)\n","    return self.fc3(x)\n","\n"],"metadata":{"id":"46TpQOkT2Coc","executionInfo":{"status":"ok","timestamp":1727527836240,"user_tz":-330,"elapsed":514,"user":{"displayName":"Shibangi Sankarsan","userId":"12830922084921040479"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UxVrBnFWZKb1"},"source":["## Part 2 - Training the AI"]},{"cell_type":"markdown","metadata":{"id":"T364fz9qZb2j"},"source":["### Setting up the environment"]},{"cell_type":"code","source":["import gymnasium as gm\n","env= gm.make('LunarLander-v2')\n","state_shape = env.observation_space.shape\n","state_size = env.observation_space.shape[0]\n","n_action= env.action_space.n\n","print(\"state shape\", state_shape)\n","print(\"state size\", state_size)\n","print(\"state shape\", n_action)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0-iKrzxK5m-o","executionInfo":{"status":"ok","timestamp":1727527842159,"user_tz":-330,"elapsed":1942,"user":{"displayName":"Shibangi Sankarsan","userId":"12830922084921040479"}},"outputId":"1a780a9b-700c-4772-96ab-27b1c21e603f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["state shape (8,)\n","state size 8\n","state shape 4\n"]}]},{"cell_type":"markdown","metadata":{"id":"c_dZmOIvZgj-"},"source":["### Initializing the hyperparameters"]},{"cell_type":"code","source":["learning_rate= 5e-4\n","minibatch_size= 100\n","discount_factor= 0.99\n","replay_buffer_size= int(1e5)\n","interpolation_parameter= 1e-3"],"metadata":{"id":"8Lv9rtXa7wrw","executionInfo":{"status":"ok","timestamp":1727527848456,"user_tz":-330,"elapsed":439,"user":{"displayName":"Shibangi Sankarsan","userId":"12830922084921040479"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8hD_Vs-bYnip"},"source":["### Implementing Experience Replay"]},{"cell_type":"code","source":["class ReplayMemory(object):\n","  def __init__(self,capacity):\n","    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    self.capacity = capacity\n","    self.memory = []\n","\n","  def push(self, event):\n","    self.memory.append(event)\n","    if len(self.memory)>self.capacity:\n","      del self.memory[0]\n","\n","  def sample(self, batch_size):\n","    experiences= random.sample(self.memory, k=batch_size)\n","    states= torch.from_numpy(np.vstack([e[0] for e in experiences if e is not None])).float().to(self.device)\n","    actions= torch.from_numpy(np.vstack([e[1] for e in experiences if e is not None])).long().to(self.device)\n","    rewards= torch.from_numpy(np.vstack([e[2] for e in experiences if e is not None])).float().to(self.device)\n","    next_states= torch.from_numpy(np.vstack([e[3] for e in experiences if e is not None])).float().to(self.device)\n","    dones= torch.from_numpy(np.vstack([e[4] for e in experiences if e is not None]).astype(np.uint8)).float().to(self.device)\n","    return states, next_states, actions, rewards, dones\n"],"metadata":{"id":"WsEhmcCeSmmV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727530975128,"user_tz":-330,"elapsed":496,"user":{"displayName":"Shibangi Sankarsan","userId":"12830922084921040479"}},"outputId":"d9c90180-b68d-41e3-c7e0-d43a94ab0547"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}]},{"cell_type":"markdown","metadata":{"id":"JmEkbFbUY6Jt"},"source":["### Implementing the DQN class"]},{"cell_type":"code","source":["class Agent():\n","  def __init__(self, states_size, action_size ):\n","    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    self.state_size= state_size\n","    self.action_size= action_size\n","    self.local_qnetwork= Network(state_size, action_size).to(self.device)\n","    self.target_qnetwork= Network(state_size, action_size).to(self.device)\n","    self.optimizer= optim.Adam(self.local_qnetwork.parameters(), lr= learning_rate)\n","    self.memory= ReplayMemory(replay_buffer_size)\n","    self.t_step=0\n","\n","  def step(self, state, action, reward,next_state, done):\n","    self.memory.push((state, action, reward,next_state, done))\n","    self.t_step=(self.t_step+1)%4\n","    if self.t_step==0:\n","      if len(self.memory.memory)> minibatch_size:\n","        experiences=self.memory.sample(100)\n","        self.learn(experiences,discount_factor)\n","\n","  def act(self,state,epsilon=0.):\n","    state=torch.from_numpy(state).float().unsqueeze(0).to(self.device)\n","    self.local_qnetwork.eval()\n","    with torch.no_grad():\n","      action_values=self.local_qnetwork(state)\n","    self.local_qnetwork.train()\n","    if random.random() > epsilon:\n","      return np.argmax(action_values.cpu().data.numpy())\n","    else:\n","      return random.choice(np.arange(self.action_size))\n","\n","  def learn(self,experiences,discount_factor):\n","    states, next_states, actions, rewards, dones=experiences\n","    next_q_target= self.target_qnetwork(next_states).detach().max(1)[0].unsqueeze(1)\n","    q_target=rewards+(discount_factor*next_q_target*(1-dones))\n","    q_expected= self.local_qnetwork(states).gather(1,actions)\n","    loss= F.mse_loss(q_expected,q_target)\n","    self.optimizer.zero_grad()\n","    loss.backward()\n","    self.optimizer.step()\n","    self.soft_update(self.local_qnetwork, self.target_qnetwork, interpolation_parameter)\n","\n","  def soft_update(self, local_model, target_model, interpolation_parameter):\n","    for target_param, local_param in zip(target_model.parameters(),local_model.parameters()):\n","      target_param.data.copy_(interpolation_parameter*local_param.data+(1.0-interpolation_parameter)*target_param.data)\n","\n","\n"],"metadata":{"id":"NmjhtOniYKX2","executionInfo":{"status":"ok","timestamp":1727530978815,"user_tz":-330,"elapsed":425,"user":{"displayName":"Shibangi Sankarsan","userId":"12830922084921040479"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o1tZElccZmf6"},"source":["### Initializing the DQN agent"]},{"cell_type":"code","source":["agent= Agent(state_size ,n_action)\n"],"metadata":{"id":"aCqh4Fb3bLOn","executionInfo":{"status":"ok","timestamp":1727530983402,"user_tz":-330,"elapsed":545,"user":{"displayName":"Shibangi Sankarsan","userId":"12830922084921040479"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E8v0PtUfaVQp"},"source":["### Training the DQN agent"]},{"cell_type":"code","source":["number_episodes= 2000\n","max_timesteps= 1000\n","epsilon_startval=1.0\n","epsilon_endvalue= 0.01\n","epsilon_decayvalue= 0.995\n","epsilon =epsilon_startval\n","scores= deque(maxlen=100)\n","\n","for episode in range(1, number_episodes+1):\n","  state,_=env.reset()\n","  score=0\n","  for T in range(max_timesteps):\n","    action= agent.act(state, epsilon)\n","    next_state, reward,done, _, _= env.step(action)\n","    agent.step(state,action,reward,next_state,done)\n","    state=next_state\n","    score+=reward\n","    if done:\n","      break\n","  scores.append(score)\n","  epsilon= max(epsilon_endvalue, epsilon_decayvalue*epsilon)\n","  print(\"\\rEpisode {}\\t Average score : {:.2f}\".format(episode,np.mean(scores)),end=\"\")\n","  if episode%100==0:\n","    print(\"\\rEpisode {}\\t Average score : {:.2f}\".format(episode,np.mean(scores)))\n","  if np.mean(scores)>=200.0:\n","    print(\"\\nEnvironment solved in {:d} episodes! \\t Average score : {:.2f}\".format(episode-100,np.mean(scores)))\n","    torch.save(agent.local_qnetwork.state_dict(),'checkpoint.pth')\n","    break\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MoE3TZ3RsCy9","executionInfo":{"status":"ok","timestamp":1727532082847,"user_tz":-330,"elapsed":250391,"user":{"displayName":"Shibangi Sankarsan","userId":"12830922084921040479"}},"outputId":"ef7fe748-4614-4a06-9433-7dcb1db7cd00"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Episode 100\t Average score : -100.54\n","Episode 200\t Average score : -25.74\n","Episode 300\t Average score : 63.37\n","Episode 400\t Average score : 185.49\n","Episode 417\t Average score : 200.45\n","Environment solved in 317 episodes! \t Average score : 200.45\n"]}]},{"cell_type":"markdown","metadata":{"id":"O8CNwdOTcCoP"},"source":["## Part 3 - Visualizing the results"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"cb9nVvU2Okhk","colab":{"base_uri":"https://localhost:8080/","height":421},"executionInfo":{"status":"error","timestamp":1727532964267,"user_tz":-330,"elapsed":522,"user":{"displayName":"Shibangi Sankarsan","userId":"12830922084921040479"}},"outputId":"184d9a91-e3d6-469c-c5fa-9382a6676093"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n"]},{"output_type":"error","ename":"ValueError","evalue":"too many values to unpack (expected 2)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-b5c1eb7191f1>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'video.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mshow_video_of_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LunarLander-v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-35-b5c1eb7191f1>\u001b[0m in \u001b[0;36mshow_video_of_model\u001b[0;34m(agent, env_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_video_of_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}],"source":["import glob\n","import io\n","import base64\n","import imageio\n","from IPython.display import HTML, display\n","from gym.wrappers.monitoring.video_recorder import VideoRecorder\n","\n","def show_video_of_model(agent, env_name):\n","    env = gym.make(env_name, render_mode='rgb_array')\n","    state, _ = env.reset()\n","    done = False\n","    frames = []\n","    while not done:\n","        frame = env.render()\n","        frames.append(frame)\n","        action = agent.act(state)\n","        state, reward, done, _, _ = env.step(action.item())\n","    env.close()\n","    imageio.mimsave('video.mp4', frames, fps=30)\n","\n","show_video_of_model(agent, 'LunarLander-v2')\n","\n","def show_video():\n","    mp4list = glob.glob('*.mp4')\n","    if len(mp4list) > 0:\n","        mp4 = mp4list[0]\n","        video = io.open(mp4, 'r+b').read()\n","        encoded = base64.b64encode(video)\n","        display(HTML(data='''<video alt=\"test\" autoplay\n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","             </video>'''.format(encoded.decode('ascii'))))\n","    else:\n","        print(\"Could not find video\")\n","\n","show_video()"]}],"metadata":{"colab":{"provenance":[{"file_id":"1aTAGb5YWBe0rNk62aFJIxAOfq5_E3Y3B","timestamp":1722698352011},{"file_id":"1IXSqYOFw40oO-rJW683jtVFEUV-A6ZDS","timestamp":1695853573029}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}